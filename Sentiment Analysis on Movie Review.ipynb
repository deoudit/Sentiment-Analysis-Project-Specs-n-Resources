{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, string, re, spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_files = glob.glob(\"train/pos/*.txt\")\n",
    "train_neg_files = glob.glob(\"train/neg/*.txt\")\n",
    "train_pos_ls = []\n",
    "\n",
    "for i in train_pos_files:\n",
    "    file = open(i, \"r\", encoding=\"utf8\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_pos_ls.append(str)\n",
    "    \n",
    "train_neg_ls = []\n",
    "for i in train_neg_files:\n",
    "    file = open(i, \"r\", encoding=\"utf8\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_neg_ls.append(str)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['reveiw', 'label']\n",
    "df_train_pos = pd.DataFrame()\n",
    "df_train_pos['review'] = train_pos_ls\n",
    "df_train_pos['label'] = 1\n",
    "df_train_neg = pd.DataFrame()\n",
    "df_train_neg['review'] = train_neg_ls\n",
    "df_train_neg['label'] = -1\n",
    "df_train = pd.concat([df_train_pos , df_train_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_files = glob.glob(\"test/pos/*.txt\")\n",
    "test_neg_files = glob.glob(\"test/neg/*.txt\")\n",
    "test_pos_ls = []\n",
    "for i in test_pos_files:\n",
    "    file = open(i, \"r\", encoding=\"utf8\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    test_pos_ls.append(str)\n",
    "    \n",
    "test_neg_ls = []\n",
    "for i in test_neg_files:\n",
    "    file = open(i, \"r\", encoding=\"utf8\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    test_neg_ls.append(str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              review  label\n",
       "0  I went and saw this movie last night after bei...      1\n",
       "1  Actor turned director Bill Paxton follows up h...      1\n",
       "2  As a recreational golfer with some knowledge o...      1\n",
       "3  I saw this film in a sneak preview, and it is ...      1\n",
       "4  Bill Paxton has taken the true story of the 19...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I went and saw this movie last night after bei...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Actor turned director Bill Paxton follows up h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>As a recreational golfer with some knowledge o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I saw this film in a sneak preview, and it is ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bill Paxton has taken the true story of the 19...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "labels = ['reveiw', 'label']\n",
    "df_test_pos = pd.DataFrame()\n",
    "df_test_pos['review'] = test_pos_ls\n",
    "df_test_pos['label'] = 1\n",
    "df_test_neg = pd.DataFrame()\n",
    "df_test_neg['review'] = test_neg_ls\n",
    "df_test_neg['label'] = -1\n",
    "df_test = pd.concat([df_test_pos , df_test_neg])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text pre-processing functions\n",
    "lemma = WordNetLemmatizer()\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "# nltk stopwords removal performs better than spacy \n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "            \n",
    "def text_prep(text):\n",
    "    no_punct = [char for char in text if char not in string.punctuation]\n",
    "    text = \"\".join(no_punct)\n",
    "    text = [lemma.lemmatize(text, pos='v') for text in text.lower().split() if text not in stops] \n",
    "    text = \" \".join(text)\n",
    "    return (text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         prep_review  label\n",
       "0  bromwell high cartoon comedy run time program ...      1\n",
       "1  homelessness houselessness george carlin state...      1\n",
       "2  brilliant overact lesley ann warren best drama...      1\n",
       "3  easily underrate film inn brook cannon sure fl...      1\n",
       "4  typical mel brook film much less slapstick mov...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prep_review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bromwell high cartoon comedy run time program ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>homelessness houselessness george carlin state...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>brilliant overact lesley ann warren best drama...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>easily underrate film inn brook cannon sure fl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>typical mel brook film much less slapstick mov...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_train['prep_review'] = df_train['review'].apply(lambda x:text_prep(x))\n",
    "df_train[['prep_review', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         prep_review  label\n",
       "0  go saw movie last night coax friends mine ill ...      1\n",
       "1  actor turn director bill paxton follow promise...      1\n",
       "2  recreational golfer knowledge sport history pl...      1\n",
       "3  saw film sneak preview delightful cinematograp...      1\n",
       "4  bill paxton take true story 1913 us golf open ...      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prep_review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>go saw movie last night coax friends mine ill ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>actor turn director bill paxton follow promise...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>recreational golfer knowledge sport history pl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>saw film sneak preview delightful cinematograp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bill paxton take true story 1913 us golf open ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# preprocess testing data\n",
    "df_test['prep_review'] = df_test['review'].apply(lambda x:text_prep(x))\n",
    "df_test[['prep_review', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing training data \n",
    "tfidf = TfidfVectorizer()\n",
    "# tfidf = TfidfVectorizer(ngram_range = (1,3)) did not improve accuracy\n",
    "x_train = tfidf.fit_transform(df_train['prep_review'])\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing testing data \n",
    "x_test = tfidf.transform(df_test['prep_review'])\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver = 'lbfgs', n_jobs = -1)\n",
    "LR.fit(x_train, y_train)\n",
    "LR_clf = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.93528"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "LR.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.88336"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "accuracy_score(y_test, LR_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVM = LinearSVC()\n",
    "LSVM.fit(x_train, y_train)\n",
    "LSVM_clf = LSVM.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.99128"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "LSVM.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.87264"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "accuracy_score(y_test, LSVM_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA = AdaBoostClassifier(n_estimators=100)\n",
    "ADA.fit(x_train, y_train)\n",
    "ADA_clf = ADA.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.84076"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "ADA.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.83188"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "accuracy_score(y_test, ADA_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=100, random_state = 42, n_jobs = -1)\n",
    "RFC.fit(x_train, y_train)\n",
    "RFC_clf = RFC.predict(x_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84712"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, RFC_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(x_train, y_train)\n",
    "MNB_clf = MNB.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9172"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "MNB.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83308"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, MNB_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_NN = TfidfVectorizer(max_features = 1000)\n",
    "# x_train_NN = tfidf_NN.fit_transform(df_train['prep_review'])\n",
    "# y_train_NN = df_train['label']\n",
    "# x_test_NN = tfidf_NN.transform(df_test['prep_review'])\n",
    "# y_test_NN = df_test['label']\n",
    "# x_train_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Convolution1D, Flatten, Dropout, Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_shape=(1000,) , activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(160, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(120, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(80, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_NN, y_train_NN, batch_size=128, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x_train_NN, y_train_NN)\n",
    "# print (loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(x_test_NN)\n",
    "# # round predictions\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# predictions = rounded\n",
    "# score = accuracy_score(y_test_NN ,predictions)\n",
    "# print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}